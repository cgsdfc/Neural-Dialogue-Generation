"""
Script to extract most common (frequent) responses from a list of responses
generated by the decoder.

Those whose frequency larger than a threshold will be considered *most common* one.
Note this is not the top N most frequent filtering.

The format of output is:

    1 2 34 4 3 2|21

where left hand side of the bar is the top response and right hand side is its frequency.
"""
from __future__ import print_function

import argparse
import collections
import logging

# Frequency >= this value is considered as generic.
FREQ_THRESHOLD = 100


def find_generic_responses(filename):
    def get_response(file):
        """
        Iterate the responses from a file. The right hand side of the bar is the response.
        :param file:
        :return:
        """
        for line in file:
            yield line.split('|')[-1]

    with open(filename) as f:
        responses = list(get_response(f))
    logging.info('number of lines: %d', len(responses))
    counter = collections.Counter(responses)
    return [item for item in counter.items() if item[1] >= FREQ_THRESHOLD]


def load_dict(file):
    """
    Create a vocab dict from a file.
    Index starts from 0, which is for the unknown token.

    :param file:
    :return:
    """
    with open(file) as f:
        return {string: idx for idx, string in enumerate(f.read().splitlines())}


def to_numbers(line, dictionary):
    """
    Turn a nature language sentence string to a list of numbers.
    :param line:
    :param dictionary:
    :return:
    """
    return [dictionary[string] for string in line.split()]


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    parser = argparse.ArgumentParser()
    parser.add_argument('input_file')
    parser.add_argument('output_file')
    parser.add_argument('-dictPath', default='data/movie_25000', help='dictionary file')
    args = parser.parse_args()

    dictionary = load_dict(args.dictPath)
    top_responses = find_generic_responses(args.input_file)
    logging.info('number of top responses: %d', len(top_responses))

    with open(args.output_file, 'w') as f:
        for text, freq in top_responses:
            ids = to_numbers(text, dictionary)
            ids = ' '.join(map(str, ids))
            f.write('%s|%s\n' % (ids, freq))
